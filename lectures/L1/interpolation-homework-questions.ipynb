{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ACSE-3 (Numerical Methods) <a class=\"tocSkip\">\n",
    "\n",
    "## Lecture 1: Interpolation and Curve Fitting <a class=\"tocSkip\">\n",
    "    \n",
    "### Homework Exercises  <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Homework\" data-toc-modified-id=\"Homework-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Homework</a></span><ul class=\"toc-item\"><li><span><a href=\"#Homework---Fitting-two-data-points\" data-toc-modified-id=\"Homework---Fitting-two-data-points-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Homework - Fitting two data points</a></span></li><li><span><a href=\"#Homework---Newton-polynomial\" data-toc-modified-id=\"Homework---Newton-polynomial-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Homework - Newton polynomial</a></span></li><li><span><a href=\"#Homework---Error-bound-for-polynomial-interpolation-of-the-Runge-function-[$\\star$]\" data-toc-modified-id=\"Homework---Error-bound-for-polynomial-interpolation-of-the-Runge-function-[$\\star$]-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Homework - Error bound for polynomial interpolation of the Runge function [$\\star$]</a></span></li><li><span><a href=\"#Homework---Chebyshev-interpolation-[$\\star$]\" data-toc-modified-id=\"Homework---Chebyshev-interpolation-[$\\star$]-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Homework - Chebyshev interpolation [$\\star$]</a></span></li><li><span><a href=\"#Homework---Chebyshev-polynomials-as-basis-functions-[$\\star\\star$]\" data-toc-modified-id=\"Homework---Chebyshev-polynomials-as-basis-functions-[$\\star\\star$]-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Homework - Chebyshev polynomials as basis functions [$\\star\\star$]</a></span></li><li><span><a href=\"#Homework---Cubic-spline-interpolation-[$\\star\\star$]\" data-toc-modified-id=\"Homework---Cubic-spline-interpolation-[$\\star\\star$]-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Homework - Cubic spline interpolation [$\\star\\star$]</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cubic-spline----derivation\" data-toc-modified-id=\"Cubic-spline----derivation-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Cubic spline -  derivation</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# as this lecture is about interpolation we will make use of this library\n",
    "import scipy.interpolate as si\n",
    "\n",
    "# some default font sizes for plots\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'Dejavu Sans']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Fitting two data points\n",
    "\n",
    "We stated in class that:\n",
    "\n",
    "\n",
    "The polynomial that fits the two data points $\\{(x_0,y_0),(x_1,y_1)\\}$ is clearly the linear function given by\n",
    "\n",
    "$$ y = f(x) \\equiv a_0 + a_1\\,x \\;\\;\\;\\;\\; \\text{i.e. the degree one polynomial:} \\;\\;\\;\\;\\; y = P_1(x) \\equiv a_0 + a_1\\,x$$\n",
    "\n",
    "where through substitution we arrive at  two simultaneous equations (or a $2\\times 2$ matrix system) which can fairly easily be solved by substituting one equation into the other to conclude that\n",
    "\n",
    "$$ a_0 = y_0 - \\frac{y_1-y_0}{x_1-x_0}x_0, \\;\\;\\;\\;\\;\\;\\;\\; a_1 = \\frac{y_1-y_0}{x_1-x_0}. $$\n",
    "\n",
    "Form the set of two simultaneous equations and solve by hand to derive this solution for the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Newton polynomial\n",
    "\n",
    "From the lecture we defined the Newton polynomial as\n",
    "\n",
    "$$ P_N(x) = a_0 +(x-x_0)a_1 + (x-x_0)(x-x_1)a_2 + \\cdots + (x-x_0)(x-x_1)\\ldots(x-x_N)a_N,$$\n",
    "\n",
    "where $a_0, a_1, \\ldots, a_N$ are our $N+1$ free parameters we need to find using the $N+1$ pieces of information we have in the given data.\n",
    "\n",
    "We introduced the divided difference notation\n",
    "\n",
    "\\begin{alignat*}{2}\n",
    "\\Delta y_i &= \\frac{y_i-y_0}{x_i-x_0},\\;\\;    && i=1,2,\\ldots, N,\\\\[10pt]\n",
    "\\Delta^2 y_i &= \\frac{\\Delta y_i-\\Delta y_1}{x_i-x_1},\\;\\;    && i=2, 3,\\ldots, N,\\\\[10pt]\n",
    "&\\vdots\\\\[5pt]\n",
    "\\Delta^N y_N &= \\frac{\\Delta^{N-1} y_N-\\Delta^{N-1} y_{N-1}}{x_N-x_{N-1}},\n",
    "\\end{alignat*}\n",
    "\n",
    "\n",
    "and saw that the unknown coefficients $a$ are given by\n",
    "\n",
    "\n",
    "$$a_0=y_0,\\;\\;\\;\\;\\; a_1 = \\Delta y_1, \\;\\;\\;\\;\\; a_2 = \\Delta^2 y_2, \\;\\;\\;\\;\\; \\ldots \\;\\;\\;\\;\\; a_N = \\Delta^N y_N.$$\n",
    "\n",
    "\n",
    "Based upon the following pseudo code implement functions to (1) calculate the coefficients of the Newton polynomial, and (2) evaluate it for the purposes of plotting. Check visually that your plotted curve of the interpolant agrees with what we saw for the Lagrange polynomial (obtained either with SciPy our our own implementation: `Lagrange_basis_poly` and `Lagrange_interp_poly`) and passes through our data points - use the same data made up of 6 points we used in the lecture:\n",
    "\n",
    "``` Python\n",
    "xi = np.array([0.5, 2.0, 4.0, 5.0, 7.0, 9.0])\n",
    "yi = np.array([0.5, 0.4, 0.3, 0.1, 0.9, 0.8])\n",
    "```\n",
    "\n",
    "*Pseudo-code / code skeleton:*\n",
    "\n",
    "``` Python\n",
    "def calculate_newton_poly_coeffs(xi, yi):\n",
    "    \"\"\" Evaluate the coefficients a_i recursively using Newton's method\n",
    "    \"\"\"\n",
    "    # initialise the array 'a' with yi, but take a copy to ensure we don't\n",
    "    # overwrite our yi data!\n",
    "    a = yi.copy()\n",
    "\n",
    "    # we have N+1 data points, and so\n",
    "    N = len(a) - 1\n",
    "\n",
    "    # for each k, we compute Δ^k y_i from the a_i = Δ^(k-1) y_i of the previous iteration:\n",
    "    for k in range(1, N+1):\n",
    "        # but only for i>=k\n",
    "        for i in range(k, N+1):\n",
    "            a[i] = *** you need to fill in the maths here ***\n",
    "\n",
    "    return a\n",
    "    \n",
    "    \n",
    "def eval_newton_poly(a, xi, x):\n",
    "    \"\"\" Function to evaluate the Newton polynomial\n",
    "    at x, given the data point xi and the polynomial coeffs a\n",
    "    \"\"\"\n",
    "    N = len(xi) - 1  # polynomial degree\n",
    "    # recursively build up polynomial evaluated at xx\n",
    "    P = a[N]\n",
    "    for k in range(1, N+1):\n",
    "        P = *** you need to fill in the maths here ***\n",
    "        \n",
    "    return P\n",
    "    \n",
    "# set up figure\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "# add a small margin \n",
    "ax1.margins(0.1)\n",
    "\n",
    "# Evaluate the coefficients of the Newton polynomial\n",
    "a = calculate_newton_poly_coeffs(xi, yi)\n",
    "# Evaluate the polynomial at high resolution and plot\n",
    "x = np.linspace(0.4, 9.1, 100)\n",
    "ax1.plot(x, eval_poly(a, xi, x), 'b', label='Newton poly')\n",
    "\n",
    "# Overlay raw data\n",
    "plot_raw_data(xi, yi, ax1)\n",
    "ax1.set_title('Newton interpolating polynomial (our implementation)', fontsize=16)\n",
    "\n",
    "# Add a legend\n",
    "ax1.legend(loc='best', fontsize=14);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Error bound for polynomial interpolation of the Runge function [$\\star$]\n",
    "\n",
    "In ACSE-2 we introduced SymPy - a library that can be used for symbolic mathematical operations.\n",
    "\n",
    "To use it to calculate and plot the derivatives of the Runge function for example we can do something like\n",
    "\n",
    "``` Python\n",
    "import sympy\n",
    "\n",
    "x = sympy.Symbol('x', real=True)\n",
    "f = 1. / (1. + 25. * x**2)\n",
    "print(\"f(x) = \", (sympy.simplify(f)))\n",
    "f_ = sympy.lambdify(x,f)\n",
    "\n",
    "dfdx = sympy.diff(f, x) \n",
    "print(\"f'(x) = \", (sympy.simplify(dfdx)))\n",
    "dfdx_ = sympy.lambdify(x,dfdx)\n",
    "\n",
    "dfdx2 = sympy.diff(dfdx, x) \n",
    "print(\"f''(x) = \", (sympy.simplify(dfdx2)))\n",
    "dfdx2_ = sympy.lambdify(x,dfdx2)\n",
    "\n",
    "dfdx3 = sympy.diff(dfdx2, x) \n",
    "print(\"f'''(x) = \", (sympy.simplify(dfdx3)))\n",
    "dfdx3_ = sympy.lambdify(x,dfdx3)\n",
    "\n",
    "xf = np.linspace(-1.0, 1.0, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(12, 4))\n",
    "fig.tight_layout(w_pad=3, h_pad=4)\n",
    "ax[0].plot(xf, f_(xf), 'b'); ax[0].set_title(\"f(x)\")\n",
    "ax[1].plot(xf, dfdx_(xf), 'b'); ax[1].set_title(\"f'(x)\")\n",
    "ax[2].plot(xf, dfdx2_(xf), 'b'); ax[2].set_title(\"f''(x)\")\n",
    "ax[3].plot(xf, dfdx3_(xf), 'b'); ax[3].set_title(\"f'''(x)\")\n",
    "```\n",
    "\n",
    "and to compute an $(N+1)$-st derivative, say, we could do something like\n",
    "\n",
    "``` Python\n",
    "N = 10\n",
    "df = f\n",
    "for i in range(N+1):\n",
    "    df = sympy.diff(df, x) \n",
    "```\n",
    "\n",
    "Play around a bit with SymPy and try plotting our error bound \n",
    "\n",
    "$$\\left| f(x) - P_N(x) \\right| \\le \\frac{1}{(N+1)!}\\, M\\, \\left|\\Psi_N(x)\\right|\n",
    "\\;\\;\\;\\;\\;\\;\\text{where}\\;\\;\\;\\;\\;\\;\n",
    "M:=\\max_{x\\in(a,b)}\\, \\left| f^{(N+1)}(x) \\right|,$$ \n",
    "\n",
    "you should see that as you increase $N$ the error bound gets larger quite rapidly and more and more focused at the end points of our interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Chebyshev interpolation [$\\star$]\n",
    "\n",
    "Consider the cell in the lecture where we computed and plotted the Chebyshev interpolant using a call to `si.lagrange` (from inside the function `plot_approximation`), i.e. where the loop read\n",
    "\n",
    "``` Python\n",
    "for i, degree in enumerate(degrees):\n",
    "    # the Chebyshev nodes\n",
    "    xi = np.cos((2.0 * np.arange(1, degree+2) - 1.0) * np.pi / (2.0 * (degree+1)))\n",
    "    # compute and plot the Lagrange polynomial using Chebyshev nodes as data locations\n",
    "    plot_approximation(runge, xi, ax[i])\n",
    "    ax[i].plot(xi, runge(xi), 'ko', label='data')\n",
    "    ax[i].set_title('Degree %i' % degree, fontsize=12)\n",
    "    ax[i].legend(loc='best', fontsize=12)\n",
    "```\n",
    "\n",
    "Recreate the four plots that resulted, but update the code (specifically our function `plot_approximation`) so that it instead calls our Lagrangian interpolation function `Lagrange_interp_poly`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Chebyshev polynomials as basis functions [$\\star\\star$]\n",
    "\n",
    "Recall from lectures that the degree $N$ Lagrange polynomial interpolating $N+1$ data points is given by\n",
    "\n",
    "$$L(x) := \\sum_{i=0}^{N} y_i \\ell_i(x),$$\n",
    "\n",
    "where the $\\ell_i(x)$ are the Lagrange basis functions defined by\n",
    "\n",
    "$$\\ell_i(x) := \\prod_{\\begin{smallmatrix}0\\le m\\le N\\\\ m\\neq i\\end{smallmatrix}} \\frac{x-x_m}{x_i-x_m},$$\n",
    "\n",
    "[note that each of these basis functions is itself a degree $N$ polynomial].\n",
    "\n",
    "A general result is the following:\n",
    "\n",
    "If the $N+1$ data locations, $x_0 < x_1 < \\ldots < x_N,$ are the roots of some (N+1) degree polynomial $\\phi_{N+1}(x)$  (from an [*orthogonal family* of polynomials](https://en.wikipedia.org/wiki/Orthogonal_polynomials), e.g. the [*Chebyshev polynomials*](https://en.wikipedia.org/wiki/Chebyshev_polynomials)) we introduced in lecture and have a nice minimal error property, then the Lagrange basis functions are equivalent to \n",
    "\n",
    "$$\\ell_i(x) \\equiv \\frac{\\phi_{N+1}(x)}{(x - x_i)\\phi'_{N+1}(x_i)},$$\n",
    "\n",
    "where $\\phi'$ is the derivative of $\\phi$.  [See Chebyshev Polynomials, by J.C. Mason, D.C. Handscomb (Chapter 6)].\n",
    "\n",
    "In the specific case we discussed in class where the $x_0 < x_1 < \\ldots < x_N,$ are the roots of the Chebyshev polynomial (which was the choice which minimised the issue we had with interpolation of the Runge function) we have that the Lagrange basis functions are equivalent to\n",
    "\n",
    "$$\\ell_i(x) = \\frac{T_{N+1}(x)}{(N+1)(x - x_i)U_{N}(x_i)},$$\n",
    "\n",
    "where $T$ and $U$ are the Chebyshev polynomials of the first and second kind respectively, i.e. the Lagrange basis functions are equivalent to scaled Chebyshev polynomials.\n",
    "\n",
    "Now of course we end up at the same final interpolating polynomial as we did with the standard Lagrange polynomial approach, but now the basis functions are not all degree $N$ polynomials (as we will see in the code and web links directly below).\n",
    "\n",
    "\n",
    "Try updating our function `Lagrange_interp_poly` so that instead of calling the function `Lagrange_basis_poly` to compute the Lagrange basis functions using the expression at the top of this cell, it calls a new function which computes the basis functions in terms of the above formula involving Chebyshev polynomials of the first ($T$) and second ($U$) kind.  \n",
    "\n",
    "You can use the recurrence relations defining these families of polynomials here: <https://en.wikipedia.org/wiki/Chebyshev_polynomials#Definition>\n",
    "\n",
    "As a hint here is a function which computes the polynomial of the first kind (you'll need to code up the second kind yourself)\n",
    "\n",
    "```Python \n",
    "def Chebyshev_first_kind(N, x):\n",
    "    T = np.zeros((N+1, len(x)))\n",
    "    T[0,:] = 1\n",
    "    if N == 0:\n",
    "        return T\n",
    "    T[1,:] = x\n",
    "    if N == 1:\n",
    "        return T\n",
    "    for n in range(2, N+1):\n",
    "        T[n,:] = 2 * x * T[n-1,:] - T[n-2,:]\n",
    "    return T\n",
    "```\n",
    "\n",
    "And as a further hint, in my solution I replace these lines from `Lagrange_interp_poly`\n",
    "\n",
    "```Python\n",
    "    l = Lagrange_basis_poly(xi, x)\n",
    "    L = np.zeros_like(x)\n",
    "    for i in range(0, len(xi)):\n",
    "        L = L + yi[i]*l[i]\n",
    "```\n",
    "\n",
    "with \n",
    "\n",
    "```Python\n",
    "    T = Chebyshev_first_kind(N+1, x)\n",
    "    U = Chebyshev_second_kind(N, xi)\n",
    "    Chebyshev_interpolant = np.zeros_like(x)\n",
    "    for i in range(0, len(xi)):\n",
    "        Chebyshev_interpolant = Chebyshev_interpolant  \\\n",
    "            + yi[i]*T[-1,:]/((N+1)*(x-xi[i])*U[-1,i])\n",
    "```\n",
    "\n",
    "I called the new function `Chebyshev_interp_poly`.\n",
    "\n",
    "\n",
    "Test your answer by recreating the above plots of the approximation (obtained using `Lagrange_interp_poly`) to the Runge functions using `degrees = [5, 9, 12, 20]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Cubic spline interpolation [$\\star\\star$]\n",
    "\n",
    "Write some code to implement and plot a cubic spline and recreate the figure from class obtained using SciPy, based on the theory below. If you get this right and if you do a little bit of extrapolation outside our data range then you will see that the behaviour here does not quite agree with SciPy. Read the SciPy docs to see why this is (consider the default boundary conditions) and redo the SciPy plot to agree with your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cubic spline -  derivation\n",
    "\n",
    "[See Elementary Numerical Analysis by Kendall Atkinson page 132 and Kiusalaas page 121].\n",
    "\n",
    "There are a few different ways to derive a linear system which can be solved for the unknowns to prescribe a cubic spline. The Wikipedia entry for example formulates the problem such that it leads to a linear system for $k$ defined as the first derivatives of the spline. Here we follow a derivation where we define $k$ to the the second derivatives (or curvatures) of the spline (Atkinson uses the notation $M$ for these curvatures; Moin uses $g''$ in the text and gpp in code).\n",
    "\n",
    "Recall we cubic splines we are looking for a curve $y = f(x)$ which is cubic between the data points (the knots), and whose first and second derivatives are continuous across the knots.\n",
    "\n",
    "Use the notation $f_{i,i+1}(x)$ to denote this cubic in the interval between knot $i$ and $i+1$ (for $i = 0, \\ldots, n-1$), so\n",
    "\n",
    "$$ f_{i,i+1}(x) = \\alpha + \\beta x + \\gamma x^2 + \\delta x^3,$$\n",
    "\n",
    "with different constants ($\\alpha,\\beta,\\gamma,\\delta$) in each interval.\n",
    "\n",
    "Introduce the notation $k_i$ for the second derivative of the (overall) spline at knot $i$, then by continuity of second derivatives across $knots$, the second derivatives of $f_{i-1,i}$ and $f_{i,i+1}$ at their common knot $x_i$ must be equal,\n",
    "and this value is $k_i$:\n",
    "\n",
    "$$ k_i = f''_{i-1,i}(x) = f''_{i,i+1}(x), \\;\\;\\;\\; \\text{for} \\;\\;\\;\\;\\; i=1,\\ldots, n-1.$$\n",
    "\n",
    "In the case of *natural* splines we use the boundary at the end point of the domain\n",
    "\n",
    "$$ k_0 = k_n = 0.$$\n",
    "\n",
    "Now since $f$ is cubic, we know that $f''(x)$ must be p/w linear and continuous, i.e. on each subinterval $f''_{i,i+1}(x)$ is linear and completely defined by its values at the two knots either end of that interval ($k_i$ and $k_{i+1}$). We can use Lagrange interpolation to write this as \n",
    "\n",
    "$$ f''_{i,i+1}(x) = k_i\\ell_i(x) + k_{i+1}\\ell_{i+1}(x),$$\n",
    "\n",
    "where the Lagrange basis polynomials are (see the cell on linear interpolation in L1)\n",
    "\n",
    "$$ \\ell_i(x) = \\frac{x - x_{i+1}}{x_i-x_{i+1}}, \\;\\;\\;\\;\\;\\;\\;\\;  \\ell_{i+1}(x) = \\frac{x - x_i}{x_{i+1}-x_i}. $$\n",
    "\n",
    "Hence, \n",
    "\n",
    "$$ f''_{i,i+1}(x) = \\frac{ k_i(x - x_{i+1}) + k_{i+1}(x - x_i) }{x_i-x_{i+1}}.$$\n",
    "\n",
    "If we integrate this linear expression up twice with respect to $x$ we get\n",
    "\n",
    "$$ f_{i,i+1}(x) = \\frac{ k_i(x - x_{i+1})^3 - k_{i+1}(x - x_i)^3 }{6(x_i-x_{i+1})} + C_1 x + C_2,$$\n",
    "\n",
    "where $C_1$ and $C_2$ are two arbitrary constants of integration. The way to check this is to see that if we differentiate this twice those two terms with the constants disappear, and the first term when integrated twice does indeed give us the term on the LHS of our expression for $ f''_{i,i+1}(x) $.\n",
    "\n",
    "Now note we can also write the extra $C_1 x + C_2$ terms in the form $A(x - x_{i+1}) - B(x - x_i)$, where we have simply redefined that constants via $C_1=A-B$ and $C_2 = -Ax_{i+1} - Bx_i$. We can do this as the constants are arbitrary at this stage, and this will prove more convenient in what follows.\n",
    "\n",
    "If you're confused about this just note that \n",
    "\n",
    "$$ f_{i,i+1}(x) = \\frac{ k_i(x - x_{i+1})^3 - k_{i+1}(x - x_i)^3 }{6(x_i-x_{i+1})} + A(x - x_{i+1}) - B(x - x_i),$$\n",
    "\n",
    "for arbitrary constants $A$ and $B$ also differentiates twice to our desired expression for $ f''_{i,i+1}(x)$.\n",
    "\n",
    "So, along with the $k_i$'s being unknown at this stage, we also have two arbitrary constants on integration left to find: $A$ and $B$ (and note there is a different set of these for every interval $i=0,\\ldots, n-1$).\n",
    "\n",
    "But we have more information to impose. The first is that the spline passes through the data:\n",
    "\n",
    "$$ y_i = f_{i,i+1}(x_i) = \\frac{ k_i(x_i - x_{i+1})^3 }{6(x_i-x_{i+1})} + A(x_i - x_{i+1}), $$\n",
    "\n",
    "and so rearranging\n",
    "\n",
    "$$ A = \\frac{y_i}{x_i - x_{i+1}} - \\frac{k_i}{6}(x_i - x_{i+1}). $$\n",
    "\n",
    "Similarly\n",
    "\n",
    "$$ y_{i+1} = f_{i,i+1}(x_{i+1}) = \\frac{ - k_{i+1}(x_{i+1} - x_i)^3 }{6(x_i-x_{i+1})} - B(x_{i+1} - x_i), $$\n",
    "\n",
    "which rearranging yields\n",
    "\n",
    "$$ B = \\frac{y_{i+1}}{x_{i} - x_{i+1}} - \\frac{k_{i+1}}{6}(x_i - x_{i+1}). $$\n",
    "\n",
    "Substituting these expressions for $A$ and $B$ back into our expression above for $ f_{i,i+1}(x) $ yields the following expression for the cubic spline over each subinterval:\n",
    "\n",
    "$$ f_{i,i+1}(x) = \\frac{k_i}{6}\\left( \\frac{ (x - x_{i+1})^3 }{x_i-x_{i+1}} - (x - x_{i+1})(x_i - x_{i+1}) \\right)\n",
    "-  \\frac{k_{i+1}}{6}\\left( \\frac{ (x - x_{i})^3 }{x_i-x_{i+1}} - (x - x_{i})(x_i - x_{i+1}) \\right)\n",
    "+ \\frac{y_i(x - x_{i+1}) - y_{i+1}(x - x_{i})}{x_i - x_{i+1}}.$$\n",
    "\n",
    "[See Atkinson (5.68) and Kiusalaas (3.10)].\n",
    "\n",
    "This is the expression for the cubic spline we implement over each subinterval, once we know values for the curvatures at the knots at either end of the subinterval, i.e. $k_i$ and $k_{i+1}$.\n",
    "\n",
    "The final piece of information we have to apply to find these values is continuity of the first derivatives of the spline across the knots: \n",
    "\n",
    "$$ f'_{i-1,i}(x_i) = f'_{i,i+1}(x_i), \\;\\;\\;\\;\\;\\text{for}\\;\\;\\;\\;\\;\\; i=1, \\ldots, n-1.$$\n",
    "\n",
    "Substituting in our expression for $f_{i,i+1}(x)$ containing only the unknowns $k$'s,\n",
    "Atkinson and Kiusalaas agree that after \"a great deal of simplification\" we arrive at the system of linear/simultaneous equations\n",
    "\n",
    "$$(x_{i-1} - x_{i})k_{i-1} + 2(x_{i-1} - x_{i+1})k_i + (x_{i} - x_{i+1})k_{i+1} = 6\\left( \\frac{y_{i-1} - y_{i}}{x_{i-1} - x_{i}} - \\frac{y_{i} - y_{i+1}}{x_{i} - x_{i+1}}  \\right),  \\;\\;\\;\\;\\;\\text{for}\\;\\;\\;\\;\\;\\; i=1, \\ldots, n-1.$$\n",
    "\n",
    "We can formulate this as an $n-1$ by $n-1$ linear system, solve for $k_1, \\ldots, k_{n-1}$, combine with the natural boundary conditions $k_0=k_n=0$, and substitute these values into our expression for $f_{i,i+1}(x)$ and we are done.\n",
    "\n",
    "The final step when given a new data location, $x$, to evaluate the cubic spline at is to identify which subinterval we are in, and hence which two $k$ values to use. Note that if you want your code to do some extrapolation (as we did in the plots in class - we plotted over $[0.4, 9.1]$ even though our data we only over  $[0.4, 9]$) you will need to treat data outside all subintervals as a special case."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
